{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 5: Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Sequence to sequence architectures\n",
    "\n",
    "Encoder network: Input. Find a suitable encoding for the input sequence.\n",
    "\n",
    "Decoder network: Output. Decode the encoded input into the desired output.\n",
    "\n",
    "![](media/Screenshot.png)\n",
    "\n",
    "The first network (AlexNet) will encode the image, while the second network will decode it into the caption.\n",
    "\n",
    "![](media/Screenshot(1).png)\n",
    "\n",
    "## ## Picking the most likely sentence\n",
    "\n",
    "![](media/Screenshot(2).png)\n",
    "\n",
    "[...] \"So what the machine translation model is, is very similar to the language model,\n",
    "except that instead of always starting along with the vector of all zeros, it instead has an encoded network that figures out some representation for the input sentence, and it takes that input sentence and starts off the decoded network with representation of the input sentence rather than with the representation of all zeros.\"\n",
    "\n",
    "It will give us the probability $P(x)$ of the output beeing some english sentence given that the input is the $x$ french sentence: $P(y^{1}, ..., y^{T_y} | x)$\n",
    "\n",
    "We want find $y$ that maximizes the conditional probability:\n",
    "\n",
    "![](media/Screenshot(3).png)\n",
    "\n",
    "## ## Beam Search\n",
    "\n",
    "Beam search will consider the $b$ (beam width) most probable words for the first step.\n",
    "\n",
    "![](media/Screenshot(4).png)\n",
    "\n",
    "Given the three choices, consider what should be the next word.\n",
    "\n",
    "Suppose the 3 most probable words were: 'in', 'jane' and 'september':\n",
    "\n",
    "![](media/Screenshot(5).png)\n",
    "\n",
    "On Step #2, the model will have $b$ instances (one for each top 3 proability word).\n",
    "\n",
    "![](media/Screenshot(6).png)\n",
    "\n",
    "Then, it'll keep the three most probable pair $(ŷ^{1}, ŷ^{2})$.\n",
    "\n",
    "And now, continue the process for each pair.\n",
    "\n",
    "![](media/Screenshot(7).png)\n",
    "\n",
    "![](media/Screenshot(8).png)\n",
    "\n",
    "Like step #2, it'll evaluate the 3 outcomes with the higher probabilities for $ŷ^3$.\n",
    "\n",
    "![](media/Screenshot(9).png)\n",
    "\n",
    "And so on, until it predicts $<EOS>$.\n",
    "\n",
    "Note that for $b = 1$, Beam Search behaves like Greedy Search.\n",
    "\n",
    "## ### Refinements\n",
    "\n",
    "This is what we wanted to maximize:\n",
    "\n",
    "![](media/Screenshot(10).png)\n",
    "\n",
    "Because $0 \\le prob \\le 1$,  $\\Pi \\rightarrow 0$. Which can result in a roundoff error due to computers handling floating points.\n",
    "\n",
    "That's why we'll use the $log$.\n",
    "\n",
    "![](media/Screenshot(11).png)\n",
    "\n",
    "One way of  reducing the penalty for translating the output as longer sentences, we can add normalization parameters:\n",
    "\n",
    "![](media/Screenshot(12).png)\n",
    "\n",
    "Usually, $\\alpha = 0.7$.\n",
    "\n",
    "Not that $\\alpha = 1$ (i.ie: $1/T_y$) offers the heavier penalization, whereas $\\alpha = 0$ (i.ie: $1$)offers the lightiest penalization.\n",
    "\n",
    "## ### Error analysis\n",
    "\n",
    "![](media/Screenshot(13).png)\n",
    "\n",
    "![](media/Screenshot(14).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ### Bleu Score (bilingual evaluation understanding)\n",
    "\n",
    "[...] \"a modified precision measure in which we will give each word credit only up to the maximum number of times it appears in the reference sentences\"\n",
    "\n",
    "![](media/Screenshot(15).png)\n",
    "\n",
    "![](media/Screenshot(16).png)\n",
    "\n",
    "Then, we may define the precision for 1-gram as:\n",
    "\n",
    "![](media/Screenshot(17).png)\n",
    "\n",
    "And for n-grams:\n",
    "\n",
    "![](media/Screenshot(18).png)\n",
    "\n",
    "![](media/Screenshot(19).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Attention Model\n",
    "\n",
    "The encoder-decoder works very well for medium size sentences (10-20 words).\n",
    "\n",
    "![](media/Screenshot(20).png)\n",
    "\n",
    "An Attention Model has a general better perfomance, and even for longer sentences. Since it tries to translate like humans do: Evaluating a part of the whole at a time.\n",
    "\n",
    "![](media/Screenshot(21).png)\n",
    "\n",
    "We will not do a word by word translation.\n",
    "\n",
    "The model will be looking at a series of **attention weights**.\n",
    "\n",
    "$\\alpha$ will be our attention parameter.\n",
    "\n",
    "How much relevant is each input $x^{<t>}$?\n",
    "\n",
    "![](media/Screenshot(22).png)\n",
    "\n",
    "![](media/Screenshot(23).png)\n",
    "\n",
    "$a^{<t'>} = (a^{\\rightarrow <t'>}, a^{\\leftarrow <t'>})$\n",
    "\n",
    "![](media/Screenshot(24).png)\n",
    "\n",
    "Where $\\alpha^{<t, t'>}$ is the amount of attention that $y^{<t>}$ should pay to $a^{<t'>}$.\n",
    "\n",
    "Computing attention:\n",
    "\n",
    "![](media/Screenshot(25).png)\n",
    "\n",
    "![](media/Screenshot(26).png)\n",
    "\n",
    "![](media/Screenshot(27).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Speech Recognition\n",
    "\n",
    "![](media/Screenshot(28).png)\n",
    "\n",
    "- One approach is to use a BRNN and an Attention model:\n",
    "\n",
    "![](media/Screenshot(29).png)\n",
    "\n",
    "- We can also use a CTC (Connection is Temporal Classification):\n",
    "\n",
    "It is a many-to-many with $T_x = T_y$\n",
    "\n",
    "This network can provide outputs like this:\n",
    "\n",
    "![](media/Screenshot(30).png)\n",
    "\n",
    "Which are considered to be correct. An then, repeated characters - not following a whitespace - are collapsed. Resulting in: *the quick...*\n",
    "\n",
    "![](media/Screenshot(31).png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Trigger Word Detection\n",
    "\n",
    "![](media/Screenshot(32).png)\n",
    "\n",
    "One hack, is to output a series of $1$s after the actual activation, to slow the decrease back to $0$.\n",
    "\n",
    "![](media/Screenshot(33).png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
