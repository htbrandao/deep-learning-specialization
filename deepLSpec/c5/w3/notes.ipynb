{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 5: Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Sequence to sequence architectures\n",
    "\n",
    "Encoder network: Input. Find a suitable encoding for the input sequence.\n",
    "\n",
    "Decoder network: Output. Decode the encoded input into the desired output.\n",
    "\n",
    "![](media/Screenshot.png)\n",
    "\n",
    "The first network (AlexNet) will encode the image, while the second network will decode it into the caption.\n",
    "\n",
    "![](media/Screenshot(1).png)\n",
    "\n",
    "## ## Picking the most likely sentence\n",
    "\n",
    "![](media/Screenshot(2).png)\n",
    "\n",
    "[...] \"So what the machine translation model is, is very similar to the language model,\n",
    "except that instead of always starting along with the vector of all zeros, it instead has an encoded network that figures out some representation for the input sentence, and it takes that input sentence and starts off the decoded network with representation of the input sentence rather than with the representation of all zeros.\"\n",
    "\n",
    "It will give us the probability $P(x)$ of the output beeing some english sentence given that the input is the $x$ french sentence: $P(y^{1}, ..., y^{T_y} | x)$\n",
    "\n",
    "We want find $y$ that maximizes the conditional probability:\n",
    "\n",
    "![](media/Screenshot(3).png)\n",
    "\n",
    "## ## Beam Search\n",
    "\n",
    "Beam search will consider the $b$ (beam width) most probable words for the first step.\n",
    "\n",
    "![](media/Screenshot(4).png)\n",
    "\n",
    "Given the three choices, consider what should be the next word.\n",
    "\n",
    "Suppose the 3 most probable words were: 'in', 'jane' and 'september':\n",
    "\n",
    "![](media/Screenshot(5).png)\n",
    "\n",
    "On Step #2, the model will have $b$ instances (one for each top 3 proability word).\n",
    "\n",
    "![](media/Screenshot(6).png)\n",
    "\n",
    "Then, it'll keep the three most probable pair $(ŷ^{1}, ŷ^{2})$.\n",
    "\n",
    "And now, continue the process for each pair.\n",
    "\n",
    "![](media/Screenshot(7).png)\n",
    "\n",
    "![](media/Screenshot(8).png)\n",
    "\n",
    "Like step #2, it'll evaluate the 3 outcomes with the higher probabilities for $ŷ^3$.\n",
    "\n",
    "![](media/Screenshot(9).png)\n",
    "\n",
    "And so on, until it predicts $<EOS>$.\n",
    "\n",
    "Note that for $b = 1$, Beam Search behaves like Greedy Search.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ### Refinements\n",
    "\n",
    "This is what we wanted to maximize:\n",
    "\n",
    "![](media/Screenshot(10).png)\n",
    "\n",
    "Because $0 \\le prob \\le 1$,  $\\Pi \\rightarrow 0$. Which can result in a roundoff error due to computers handling floating points.\n",
    "\n",
    "That's why we'll use the $log$.\n",
    "\n",
    "![](media/Screenshot(11).png)\n",
    "\n",
    "One way of  reducing the penalty for translating the output as longer sentences, we can add normalization parameters:\n",
    "\n",
    "![](media/Screenshot(12).png)\n",
    "\n",
    "Usually, $\\alpha = 0.7$.\n",
    "\n",
    "Not that $\\alpha = 1$ (i.ie: $1/T_y$) offers the heavier penalization, whereas $\\alpha = 0$ (i.ie: $1$)offers the lightiest penalization.\n",
    "\n",
    "\n",
    "![](media/Screenshot(13).png)\n",
    "\n",
    "![](media/Screenshot(14).png)\n",
    "\n",
    "![](media/Screenshot(15).png)\n",
    "\n",
    "![](media/Screenshot(16).png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/home/rique/Downloads/Screenshot(1).png' -> 'media/Screenshot(1).png'\n",
      "'/home/rique/Downloads/Screenshot(10).png' -> 'media/Screenshot(10).png'\n",
      "'/home/rique/Downloads/Screenshot(11).png' -> 'media/Screenshot(11).png'\n",
      "'/home/rique/Downloads/Screenshot(12).png' -> 'media/Screenshot(12).png'\n",
      "'/home/rique/Downloads/Screenshot(2).png' -> 'media/Screenshot(2).png'\n",
      "'/home/rique/Downloads/Screenshot(3).png' -> 'media/Screenshot(3).png'\n",
      "'/home/rique/Downloads/Screenshot(4).png' -> 'media/Screenshot(4).png'\n",
      "'/home/rique/Downloads/Screenshot(5).png' -> 'media/Screenshot(5).png'\n",
      "'/home/rique/Downloads/Screenshot(6).png' -> 'media/Screenshot(6).png'\n",
      "'/home/rique/Downloads/Screenshot(7).png' -> 'media/Screenshot(7).png'\n",
      "'/home/rique/Downloads/Screenshot(8).png' -> 'media/Screenshot(8).png'\n",
      "'/home/rique/Downloads/Screenshot(9).png' -> 'media/Screenshot(9).png'\n",
      "'/home/rique/Downloads/Screenshot.png' -> 'media/Screenshot.png'\n"
     ]
    }
   ],
   "source": [
    "!cp -vf /home/rique/Downloads/Screenshot*.png media/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
