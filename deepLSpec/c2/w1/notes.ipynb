{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 2: Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Data\n",
    "\n",
    "## ## Sets\n",
    "\n",
    "[...] 'take all the data you have and carve off some portion of it to  be your **training set**. Some portion of it to be your *hold-out cross validation set*, and *this is sometimes also called the development set*. And for brevity I'm just going to call this the **dev set**, but all of these terms mean roughly the same thing.'\n",
    "\n",
    "![split](./files/media/split.png)\n",
    "\n",
    "The **goal** of the dev set is that you're going to test different algorithms on it and see which algorithm works better.\n",
    "\n",
    "## ## Bias and variance\n",
    "\n",
    "*(If you never heard about 'Bias-Variance Tradeoff, there's a great TLDR [here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=2ahUKEwj14r6clYbnAhUDG7kGHZVSChoQFjAAegQIARAB&url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F4284%2Fintuitive-explanation-of-the-bias-variance-tradeoff&usg=AOvVaw1A8Yka6B1y54v36zlsXn0S))*\n",
    "\n",
    "![bv](./files/media/bv.png)\n",
    "\n",
    "Example:\n",
    "\n",
    "![bv2](./files/media/bv2.png)\n",
    "\n",
    "(*About **Bayes Error**: See [here](https://www.cs.helsinki.fi/u/jkivinen/opetus/iml/2013/Bayes.pdf)*)\n",
    "\n",
    "## ## Basic recipe\n",
    "\n",
    "![rec](./files/media/rec.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Regularization\n",
    "\n",
    "[Regularization (mathematics) - Wikipedia](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&uact=8&ved=2ahUKEwinjqyptYbnAhVKOKwKHVtsCdcQFjACegQIDRAG&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FRegularization_(mathematics)&usg=AOvVaw04AA1ClsGSf0abnrOMr_C2): \"In mathematics, statistics, and computer science, particularly in machine learning and inverse problems, regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting.\"\n",
    "\n",
    "## ## Weight Decay\n",
    "\n",
    "![wd](./files/media/wd.png)\n",
    "\n",
    "Note that, when computing the parameters update, we end up with\n",
    "\n",
    "$w^{[L]} = w^{[L]} * (1 - \\frac{alfa * lambd}m) - alfa * {\\partial w^{[L]}}$\n",
    "\n",
    "Since,\n",
    "\n",
    "(`alfa`, `lambd`, `m`) > 0\n",
    "\n",
    "Then,\n",
    "\n",
    "$(1 - \\frac{alfa * lambd}m) < 1$, \n",
    "\n",
    "And,\n",
    "\n",
    "$w^{[L]} * (1 - \\frac{alfa * lambd}m) < w^{[L]}$\n",
    "\n",
    "Which means that we are, first, performing a '*shrinking*' of $w^{[L]}$ and then updating it as we know\n",
    "\n",
    "## ### Why regularization reduces overfitting?\n",
    "\n",
    "![reg](./files/media/reg.png)\n",
    "\n",
    "[...] \"if you crank regularisation lambda to be really, really big,\n",
    "they'll be really incentivized to set the weight matrices W to be reasonably close to zero. So one piece of intuition is maybe it set the weight to be so close to zero for a lot of hidden units that's basically zeroing out a lot of the impact of these hidden units.\n",
    "And if that's the case, then this much simplified neural network becomes a much smaller neural network.\"\n",
    "\n",
    "![reg2](./files/media/reg2.png)\n",
    "\n",
    "[...] \"And so that will take you from this overfitting case much closer to the left to other high bias case. But hopefully there'll be an intermediate value of lambda that results in a result closer to this just right case in the middle. But the intuition is that by cranking up lambda to be really big they'll set W close to zero,\n",
    "which in practice this isn't actually what happens. We can think of it as zeroing out or at least reducing the impact of a lot of the hidden units so you end up with what might feel like a simpler network.\"\n",
    "\n",
    "![reg3](./files/media/reg3.png)\n",
    "\n",
    "Each 'disabled' hidden unit will have a much lower impact on data.\n",
    "\n",
    "If $lambd$ is too high, the behaviour of the network will be close to linear, which might result in a 'linear network'\n",
    "\n",
    "## ## Dropout regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv -v /home/f4119597/Downloads/Screenshot.png files/media/reg3.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ./files/media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
