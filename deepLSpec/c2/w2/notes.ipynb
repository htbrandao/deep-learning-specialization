{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Course 2: Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Mini-batch gradient descent\n",
    "\n",
    "To process your whole training set at once would demand a lot of memory. Instead, we will split our training set inti mini-batchs (smaller portions) of size $t$.\n",
    "\n",
    "Then, we run our model on each portion at a time, until it has run all of them.\n",
    "\n",
    "[...] \"$epoch$ is a word that means a single pass through the training set.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "\n",
    "One of the many parameters that we used was `number_of_iterations`. \n",
    "\n",
    "Assume,\n",
    "\n",
    "`number_of_iterations`$ = 10$,\n",
    "\n",
    "and that we split our trainig data ($X$) in 50 parts.\n",
    "\n",
    "Then, for each mini-batch $0 < i < 50$, $X^{\\{i\\}}$, we will run $X^{\\{i\\}}$ through our model a `number_of_iterations`-times.\n",
    "\n",
    "Whenever all 50 parts are done, we'll have **1 $epoch$**\n",
    "\n",
    "Which means we just got a new parameter to tune: `number of epochs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](files/media/mini.png)\n",
    "\n",
    "Pay attention to $X^{\\{i\\}}$'s and $Y^{\\{i\\}}$'s shapes:\n",
    "\n",
    "$X := (n_x, t)$ and $Y := (1, t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying vectorization:\n",
    "\n",
    "![](files/media/mini2.png)\n",
    "![](files/media/mini3.png)\n",
    "![](files/media/mini4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting $J$, we should come by something like this:\n",
    "\n",
    "![](files/media/mini5.png)\n",
    "\n",
    "(Notice that one the mini-batch scenario, each iteration over $X^{\\{i\\}}$ is as if we'd computed $J$ for our entire trainig set, and then dit it again, and appended the graphs)\n",
    "\n",
    "![](files/media/mini6.png)\n",
    "\n",
    "[...] \"**stochastic gradient descent** won't ever converge, it'll always just kind of oscillate and wander around the region of the minimum.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Exponentially weighted (moving) averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "$\\theta_i$ is the i-est day temperature\n",
    "\n",
    "![](files/media/exp.png)\n",
    "\n",
    "\n",
    "$V_t = 0.9 * V_{t-1} + 0.1 * \\theta_t$\n",
    "\n",
    "Let's define and start adjusting a parameter $\\beta$:\n",
    "\n",
    "$V_t = \\beta * V_{t-1} + (1 - beta) * \\theta_t$\n",
    "\n",
    "![](files/media/exp2.png)\n",
    "\n",
    "![](files/media/exp3.png)\n",
    "\n",
    "![](files/media/exp4.png)\n",
    "\n",
    "Thus, having a **exponentially weghted average**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ### Bias correction\n",
    "\n",
    "![](files/media/exp5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Gradient descent with momentum\n",
    "\n",
    "![](files/media/gmm.png)\n",
    "\n",
    "The best behaviour for us is\n",
    "\n",
    "![](files/media/gmm1_2.png)\n",
    "\n",
    "[...] \"And this up and down oscillations slows down gradient descent and\n",
    "prevents you from using a much larger learning rate\"\n",
    "\n",
    "[...] \"if you were to use a much larger learning rate you might end up over shooting and end up diverging\"\n",
    "\n",
    "![](files/media/gmm2.png)\n",
    "\n",
    "[...] \"So what this does is smooth out the steps of gradient descent.\"\n",
    "\n",
    "![](files/media/gmm3.png)\n",
    "\n",
    "[...] \"So, in the vertical direction, where you want to slow things down, this will average out positive and negative numbers, so the average will be close to zero. Whereas, on the horizontal direction,\n",
    "all the derivatives are pointing to the right of the horizontal direction, so the average in the horizontal direction will still be pretty big. So that's why with this algorithm, with a few iterations\n",
    "you find that the gradient descent with momentum ends up eventually just taking steps that are much smaller oscillations in the vertical direction, but are more directed to just moving quickly in the horizontal direction. And so this allows your algorithm to take a more straightforward path, or to damp out the oscillations in this path to the minimum\"\n",
    "\n",
    "![](files/media/gmm4.png)\n",
    "\n",
    "To apply the `bias correction`,\n",
    "\n",
    "$Vdw = \\frac{Vdw}{(1-\\beta^t)}$\n",
    "\n",
    "\n",
    "$Vdb = \\frac{Vdb}{(1-\\beta^t)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Root mean squared (RMS) prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](files/media/rms.png)\n",
    "\n",
    "To avoid denominator explosion, we may add $\\epsilon$ to the square root,\n",
    "\n",
    "$w := w - \\alpha * \\frac{dw}{\\sqrt{Sdw + \\epsilon}}$\n",
    "\n",
    "$b := b - \\alpha * \\frac{db}{\\sqrt{Sdb + \\epsilon}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Adam optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Local optima problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv -v /home/f4119597/Downloads/Screenshot.png ./files/media/adam.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
