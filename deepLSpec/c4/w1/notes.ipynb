{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 4: Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Convolution\n",
    "\n",
    "[What is an intuitive explanation for convolution?](https://www.quora.com/What-is-an-intuitive-explanation-for-convolution)\n",
    "\n",
    "[Intuitively Understanding Convolutions for Deep Learning](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Edge detection\n",
    "\n",
    "We'll apply a filter, running over the image matrix.\n",
    "\n",
    "The following filter (kernel) is used for vertical edge detection:\n",
    "\n",
    "![](media/ed.png)\n",
    "\n",
    "(For each iteration, this could be represented as: $line_{from\\_picture} * column_{from\\_filter}.T$)\n",
    "\n",
    "Why it works:\n",
    "\n",
    "![](media/ed2.png)\n",
    "\n",
    "[...] \"a vertical edge is where there are bright pixels on the left, you do not care that much what is in the middle and dark pixels on the right.\"\n",
    "\n",
    "![](media/ed3.png)\n",
    "\n",
    "___\n",
    "**Example:**\n",
    "\n",
    "![](media/ed4.png)\n",
    "\n",
    "___\n",
    "**Example:**\n",
    "\n",
    "![](media/ed5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Padding\n",
    "\n",
    "Default convolving will lead to lose information on the image's border/edges.\n",
    "\n",
    "![](media/padd.png)\n",
    "\n",
    "So, we could add/use padding. Which will increase the relevance of the image's borders/edges pixels and preserve the output dimmension equals to the input's.\n",
    "\n",
    "![](media/padd2.png)\n",
    "\n",
    "___\n",
    "Forms of implementing padding:\n",
    "\n",
    "![](media/padd3.png)\n",
    "\n",
    "$padding = \\frac{f - 1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Strided convolutions\n",
    "\n",
    "Works as a `step`, $(i,j)$-wise.\n",
    "\n",
    "With a padding of $p$ and a stride of $s$:\n",
    "\n",
    "\n",
    "![](media/stri.png)\n",
    "\n",
    "$i.e.:$\n",
    "\n",
    "______\n",
    "\n",
    "![](media/stri3.png)\n",
    "\n",
    "___\n",
    "\n",
    "(For non-integer values, round down (floor) the value.)\n",
    "\n",
    "The kernel product only happens when the multiplication is possible:\n",
    "\n",
    "![](media/stri2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ \n",
    "**Math:**\n",
    "\n",
    "He then explains about this twist and turn,\n",
    "\n",
    "![](media/stri4.png)\n",
    "\n",
    "**Disclaimer:**\n",
    "\n",
    "![](media/stri5.png)\n",
    "\n",
    "Achieving this result is just a matter of performin the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "[[ 3  4  5]\n",
      " [ 1  0  2]\n",
      " [-1  9  7]]\n",
      "\n",
      "output:\n",
      "[[ 7  9 -1]\n",
      " [ 2  0  1]\n",
      " [ 5  4  3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([[3, 4, 5], [1, 0, 2], [-1, 9, 7]])\n",
    "\n",
    "print('input:\\n{}'.format(v))\n",
    "\n",
    "# flipped identity matrix\n",
    "anti_id = np.array([[0, 0, 1],[0, 1, 0],[1, 0, 0]])\n",
    "\n",
    "# flip horizontally: V * anti_id\n",
    "first_step = np.dot(v, anti_id)\n",
    "\n",
    "# flip vertically: anti_id * v\n",
    "second_step = np.dot(anti_id, first_step)\n",
    "\n",
    "print('\\noutput:\\n{}'.format(second_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### Convolutions over volume (RGB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll apply convolutions, likewise, on each layer of the rgb channels.\n",
    "\n",
    "![](media/rgb.png)\n",
    "\n",
    "We could apply filters that only work on a single channel, zeroing the other layers.\n",
    "\n",
    "Convolving on volumes will allow us to operate on RGB pictures and detect more complex edges, like horizontal edges, or angled edges.\n",
    "\n",
    "![](media/rgb2.png)\n",
    "\n",
    "![](media/rgb3.png)\n",
    "\n",
    "![](media/rgb4.png)\n",
    "\n",
    "![](media/rgb5.png)\n",
    "\n",
    "![](media/rgb6.png)\n",
    "\n",
    "![](media/rgb7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If layer '$l$' is a convolution layer:\n",
    "\n",
    "$f^{[l]}$ = filter size\n",
    "\n",
    "$p^{[l]}$ = padding\n",
    "\n",
    "$s^{[l]}$ = stride\n",
    "\n",
    "\n",
    "- The input of layer '$l$' has dimension:\n",
    "\n",
    "$n_{height}^{[l-1]}$ x $n_{width}^{[l-1]}$ x $n_{c}^{[l-1]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/home/f4119597/Downloads/Screenshot.png': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!mv -v /home/f4119597/Downloads/Screenshot.png media/rgb8.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
