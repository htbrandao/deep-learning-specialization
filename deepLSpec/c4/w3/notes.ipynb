{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 4: Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Object Localization\n",
    "\n",
    "We'll output a few more numbers to form the bounding box coordinates.\n",
    "\n",
    "![](media/loc.png)\n",
    "\n",
    "$p_c$ E (0, 1) : is there an object?\n",
    "\n",
    "$b_x$, $b_y$, $b_h$, $b_w$ : bounding box coordinates\n",
    "\n",
    "$c_1$, $c_2$, $c_3$ : object class\n",
    "\n",
    "Loss:\n",
    "\n",
    "- If $y_1 = 1$:\n",
    "\n",
    "$L(ŷ, y) = (ŷ_1^{2} - y_1^{2}) + ... + (ŷ_8^{2} - y_8^{2})$\n",
    "\n",
    "- If $y_1 = 0$, when the rest of the values are **don't care**:\n",
    "\n",
    "$L(ŷ, y) = (ŷ_1^{2} - y_1^{2})$,\n",
    "___\n",
    "\n",
    "**Example:**\n",
    "\n",
    "![](media/loc1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Landmark Detection\n",
    "\n",
    "Generate a labeled training set of the key landmarks on the disered place of detection.\n",
    "\n",
    "Each landmark will have it's own $(l_x, l_y)$ coordinates.\n",
    "\n",
    "![](media/land.png)\n",
    "\n",
    "[...] \"someone will have had to go through and laboriously annotate all of these landmarks.\"\n",
    "\n",
    "**This is why we should always contribute to open source.**\n",
    "\n",
    "Note that the landmarks should be consistent acrross images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Sliding Window\n",
    "\n",
    "First, we need a labeled (and cropped) training set:\n",
    "\n",
    "![](media/od.png)\n",
    "\n",
    "We will apply a sliding window detection using a ConvNet to detect what we want ($0$ or $1$):\n",
    "\n",
    "![](media/od2.png)\n",
    "\n",
    "After striding the window on the entire image, increase the window size. And repeat the process.\n",
    "\n",
    "![](media/od3.png)\n",
    "\n",
    "This takes a high computational cost and need a fine grain to be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Convolutional Sliding Window\n",
    "\n",
    "**Example:**\n",
    "\n",
    "![](media/sw.png)\n",
    "\n",
    "We will replace the FC layers with conv layers,\n",
    "\n",
    "![](media/sw2.png)\n",
    "___\n",
    "\n",
    "**Example:**\n",
    "\n",
    "![](media/sw3.png)\n",
    "\n",
    "[...] \"instead of doing it sequentially, with this convolutional implementation that you saw in the previous slide, you can implement the entire image, all maybe 28 by 28 and convolutionally make all the predictions at the same time by one forward pass through this big convnet and hopefully have it recognize the position of the car\"\n",
    "\n",
    "![](media/sw4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Bounding box prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## YOLO - You Only Look Once\n",
    "\n",
    "First, label the data accordingly **for each block**:\n",
    "\n",
    "$y_i = [p_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3]$, where $i$ is a block index.\n",
    "\n",
    "![](media/yo.png)\n",
    "\n",
    "![](media/yo2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "Here is where I sanity checked myself.\n",
    "\n",
    "Until now there's a lot of content in this course, so I went back to **week 1** started a review.\n",
    "\n",
    "I just had a \"\"\"breakthrough\"\"\" related to a personal project where I'll need to know as much about sequence models as I can. And to master it, I really need great knowledge about CNNs.\n",
    "\n",
    "So, review it is!\n",
    "\n",
    "Today is February 26, 2020.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "A lot has happened: Work and psersonal projects, world corona pandemic, vacation days.\n",
    "I'm back.\n",
    "    \n",
    "Today is June 03, 2020.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Intersection Over Union (IOU)\n",
    "\n",
    "![](media/iou.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Non-max supression\n",
    "\n",
    "Whenever yout model yields more than one bounding box for the given image\n",
    "![](media/nm.png)\n",
    "\n",
    "Selects the rectangle weith the highest probability ($p_c$) and rules out the others with the lower $IOU$\n",
    "\n",
    "![](media/nm2.png)\n",
    "\n",
    "If yout model has to predict more then one class, your output vector will have more rows (for each possible class), and need to carry **non-max supression** independently for each class\n",
    "\n",
    "![](media/nm3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Anchor Boxes\n",
    "\n",
    "You need to pre-define shapes (anchor boxes) to try and encapsulate the possible class. \n",
    "Cars tend to be horizontal rectangle whereas people tend to be vertical rectangle. A table could be more of a square shape.\n",
    "\n",
    "![](media/bb.png)\n",
    "\n",
    "Your output vector will have a 'section' for each bounding box\n",
    "\n",
    "![](media/bb1.png)\n",
    "\n",
    "![](media/bb2.png)\n",
    "\n",
    "![](media/bb3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Region proposal: R-CNN\n",
    "\n",
    "Propose regions using image segmentation algorithm, classify proposed regions one at a time.\n",
    "\n",
    "Output label and bounding box.\n",
    "\n",
    "![](media/rcnn.png)\n",
    "\n",
    "Fast R-CNN propose regions and use convolution implementation of sliding windows to classify all the proposed regions\n",
    "\n",
    "Faster R-CNN use convolution networks do propose regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
