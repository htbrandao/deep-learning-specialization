{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Review: Week 1, 2 and mid week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dt.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 1797, 10, 1797)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt.data), len(dt.target), len(dt.target_names), len(dt.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector:\n",
      "[[ 0.  0.  0. 12. 13.  5.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16.  9.  0.  0.]\n",
      " [ 0.  0.  3. 15. 16.  6.  0.  0.]\n",
      " [ 0.  7. 15. 16. 16.  2.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  3.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16. 10.  0.  0.]]\n",
      "label:1\n"
     ]
    }
   ],
   "source": [
    "no1 = dt.images[1]\n",
    "no1_target = dt.target[1]\n",
    "\n",
    "print('vector:\\n{}\\nlabel:{}'.format(no1, no1_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above array would look like something like this:\n",
    "\n",
    "![](media/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Check below to see that I got that right lol)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL4AAADCCAYAAAD3lHgnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAJFElEQVR4nO3d34td5RnF8e/qqLRV25EmLerEjhcSkEInJQSKpaSKJVYxvehFAgpTCl5ZDC2I9sr8A5JelIJEW0GrtP5AEasVzGiFNjWJY2t+lTSkmGCbhDL+umhIfHpxTmBMJpl36H733ifP+sDgnDOHNwtZs9mzz37Oq4jALJvPdB3ArAsuvqXk4ltKLr6l5OJbSi6+pXRRjUWXLVsWk5OTNZburf379ze+5qlTpxpd76qrrmp0PYDx8fHG12zSoUOHOH78uM58vkrxJycn2bFjR42le2vt2rWNrzk3N9foeps3b250PYD169c3vmaTVq9eveDzPtWxlFx8S8nFt5RcfEupqPiS1knaL+mApPtqhzKrbdHiSxoDfgHcAlwPbJR0fe1gZjWVHPHXAAci4mBEnACeBPp9DctsESXFvxp4d97jw8PnzEZWY3/cSrpL0g5JO44dO9bUsmZVlBT/CLBi3uOJ4XOfEhEPRcTqiFi9fPnypvKZVVFS/DeB6yRdK+kSYAPwfN1YZnUteq9ORJyUdDfwMjAGPBIRu6snM6uo6Ca1iHgReLFyFrPW+J1bS8nFt5RcfEvJxbeUqkxgZVRjBO+1115rdL1t27Y1uh70fwLrXHzEt5RcfEvJxbeUXHxLycW3lFx8S8nFt5RKZm4fkXRU0jttBDJrQ8kR/9fAuso5zFq1aPEj4nXgPy1kMWuNZ24tpcaK75lbGyW+qmMpufiWUsnlzCeAPwErJR2W9KP6sczqKvmUhY1tBDFrk091LCUX31Jy8S0lF99SSjtsPjs72+h6MzMzja5Xw9TUVNcResNHfEvJxbeUXHxLycW3lFx8S8nFt5RKblJbIWmbpD2Sdku6p41gZjWVXMc/Cfw0InZJuhzYKemViNhTOZtZNSUzt+9FxK7h9x8Ce/E+tzbilnSOL2kSWAVsrxHGrC3FxZd0GfA0sCkiPljg5x42t5FRVHxJFzMo/eMR8cxCr/GwuY2Skqs6Ah4G9kbEg/UjmdVXcsS/AbgTuFHS7PDre5VzmVVVMnP7BqAWspi1xu/cWkouvqXk4ltKLr6lNBIzt1u2bGl8zQceeKDR9d5///1G16th7dq1XUfoDR/xLSUX31Jy8S0lF99ScvEtJRffUnLxLaWS25I/K+kvkt4eDptvbiOYWU0lb2D9F7gxIj4aDqS8Ien3EfHnytnMqim5LTmAj4YPLx5+Rc1QZrWVjh6OSZoFjgKvRMRZw+aeubVRUlT8iDgVEVPABLBG0tcWeI1nbm1kLOmqTkTMAduAdXXimLWj5KrOcknjw+8/B9wM7KsdzKymkqs6VwKPShpj8Ivy24h4oW4ss7pKrur8lcGnp5ldMPzOraXk4ltKLr6l5OJbSiMxbL5p06bG15yenm50vSuuuKLR9WqYm5vrOkJv+IhvKbn4lpKLbym5+JaSi28pufiW0lI2fxuT9JYk36BmI28pR/x7GOxxazbySkcPJ4Bbga1145i1o/SIvwW4F/jkXC/wzK2NkpIJrNuAoxGx83yv88ytjZLS7T5vl3QIeJLBtp+PVU1lVtmixY+I+yNiIiImgQ3AqxFxR/VkZhX5Or6ltKTbkiNiBpipksSsRT7iW0ouvqXk4ltKLr6lNBIzt9aM2dnZxtecmppqfM02+IhvKbn4lpKLbym5+JaSi28pufiWUtHlzOEtyR8Cp4CTEbG6Ziiz2pZyHf87EXG8WhKzFvlUx1IqLX4Af5C0U9JdNQOZtaH0VOdbEXFE0peBVyTti4jX579g+AtxF8A111zTcEyzZpVu8Hxk+N+jwLPAmgVe42FzGxkln7JwqaTLT38PfBd4p3Yws5pKTnW+Ajwr6fTrfxMRL1VNZVZZyT63B4Gvt5DFrDW+nGkpufiWkotvKbn4lpKLbym5+JaSi28pufiWkotvKbn4lpKLbym5+JZS6Xaf45KekrRP0l5J36wdzKym0gmsnwMvRcQPJF0CfL5iJrPqFi2+pC8C3wamASLiBHCibiyzukpOda4FjgG/kvSWpK3DSaxP8QbPNkpKin8R8A3glxGxCvgYuO/MF3nm1kZJSfEPA4cjYvvw8VMMfhHMRlbJBs//At6VtHL41E3AnqqpzCorvarzY+Dx4RWdg8AP60Uyq6+o+BExC/iDYu2C4XduLSUX31Jy8S0lF99SSrvB8/j4eKPrrV+/vtH1AJ577rlG15uZmWl0PYDp6enG12yDj/iWkotvKbn4lpKLbym5+JaSi28plWwFtFLS7LyvDyRtaiOcWS0lO6LsB6YAJI0BRxhsAGc2spZ6qnMT8I+I+GeNMGZtWWrxNwBP1Ahi1qbi4g+HUG4HfneOn3vY3EbGUo74twC7IuLfC/3Qw+Y2SpZS/I34NMcuEKUfIXgpcDPwTN04Zu0onbn9GPhS5SxmrfE7t5aSi28pufiWkotvKbn4lpIiovlFpWNAyf08y4DjjQdoVt8z9j0fdJvxqxFx1juqVYpfStKOiOj1RxP2PWPf80E/M/pUx1Jy8S2lrov/UMf/fom+Z+x7Puhhxk7P8c260vUR36wTnRRf0jpJ+yUdkHTWRnJdk7RC0jZJeyTtlnRP15nORdLYcDfKF7rOspC+bg7e+qnOcGD97wxucz4MvAlsjIje7Ksl6UrgyojYJelyYCfw/T5lPE3STxjsVvOFiLit6zxnkvQo8MeI2Hp6c/CImOs6VxdH/DXAgYg4ONws+kmg+Y8a/j9ExHsRsWv4/YfAXuDqblOdTdIEcCuwtessC5m3OfjDMNgcvA+lh26KfzXw7rzHh+lhqU6TNAmsAraf/5Wd2ALcC3zSdZBzKNocvAv+4/Y8JF0GPA1siogPus4zn6TbgKMRsbPrLOdRtDl4F7oo/hFgxbzHE8PnekXSxQxK/3hE9HHk8gbgdkmHGJwu3ijpsW4jnaW3m4N3Ufw3geskXTv8Y2cD8HwHOc5Jkhicl+6NiAe7zrOQiLg/IiYiYpLB/8NXI+KOjmN9Sp83B299K6CIOCnpbuBlYAx4JCJ2t51jETcAdwJ/kzQ7fO5nEfFih5lGVS83B/c7t5aS/7i1lFx8S8nFt5RcfEvJxbeUXHxLycW3lFx8S+l/UQOY/MBKLIMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(no1, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Vertical edge detection**\n",
    "\n",
    "Define the edge detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_edge_detector = np.array([\n",
    "                        [1, 0, -1],\n",
    "                        [1, 0, -1],\n",
    "                        [1, 0, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk over the picture\n",
    "\n",
    "def stride(_image, _filter, add_stride=0):\n",
    "    coords = []\n",
    "    h = _image.shape[0]\n",
    "    w = _image.shape[1]\n",
    "    f_h = _filter.shape[0]\n",
    "    f_w = _filter.shape[1]\n",
    "    # Note that we don't need to set default stride value\n",
    "    # of 1 because we are already iterating over the\n",
    "    # lines and columns\n",
    "    for line in range(h):\n",
    "        for col in range(w):\n",
    "            start = line, col\n",
    "            end = line + f_h + add_stride, col + f_w + add_stride\n",
    "            if end[0] <= h:\n",
    "                if end[1] <=  w:\n",
    "                    coords.append([start, end])\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dimension:\n",
    "\n",
    "$n_{height}^{[l-1]}$ x $n_{width}^{[l-1]}$ x $n_{channels}^{[l-1]}$\n",
    "\n",
    "Output dimension:\n",
    "\n",
    "$n_{height}^{[l]}$ x $n_{width}^{[l]}$ x $n_{channels}^{[l]}$\n",
    "\n",
    "**where**,\n",
    "\n",
    "$n^{[l]} = floor([\\frac{n^{[l]}+2*p^{[l]}-f}{s^{[l]}} +1]$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if** $height \\neq width$, **then**\n",
    "\n",
    "$n_{height}^{[l]} = floor([\\frac{n_{height}^{[l]}+2*p^{[l]}-f}{s^{[l]}} +1]$)\n",
    "\n",
    "**and**,\n",
    "\n",
    "$n_{width}^{[l]} = floor([\\frac{n_{width}^{[l]}+2*p^{[l]}-f}{s^{[l]}}+1]$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the convolution\n",
    "    \n",
    "def conv2d(_image, _filter, add_stride=0, verbose=True):\n",
    "    convs = []\n",
    "    coords = stride(_image, _filter, add_stride)\n",
    "    f_x = _filter.shape[0]\n",
    "    f_y = _filter.shape[1]\n",
    "    for c in coords:\n",
    "        # start\n",
    "        s_x = c[0][0]\n",
    "        s_y = c[0][1]\n",
    "        # end\n",
    "        e_x = c[1][0]\n",
    "        e_y = c[1][1]\n",
    "        window = _image[s_x:e_x, s_y:e_y]\n",
    "        conv = window * _filter\n",
    "        det = np.sum(conv)\n",
    "        convs.append(det)\n",
    "        if verbose == True:\n",
    "            print('Coords: {}'.format(c))\n",
    "            print('Slice:\\n{}'.format(window))\n",
    "            print('Conv:\\n{}'.format(conv))\n",
    "            print('Sum: {}'.format(det) + '\\n')\n",
    "    # We need to save the results from each convolution\n",
    "    # in our new convolution result matrix\n",
    "    # The result matrix shall have height and width:\n",
    "    # (h_prev - filter_h) + 1\n",
    "    r_h = _image.shape[0] - f_x + 1\n",
    "    r_w = _image.shape[1] - f_y + 1\n",
    "    # Now, fill in the values from the convolution\n",
    "    # into the result matrix\n",
    "    r = np.array(convs).reshape(r_h, r_w)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case I**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10, 10, 10,  0,  0,  0],\n",
       "        [10, 10, 10,  0,  0,  0],\n",
       "        [10, 10, 10,  0,  0,  0],\n",
       "        [10, 10, 10,  0,  0,  0],\n",
       "        [10, 10, 10,  0,  0,  0],\n",
       "        [10, 10, 10,  0,  0,  0]]), (6, 6))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_array = np.array([\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0]\n",
    "    ])\n",
    "\n",
    "vertical_array, vertical_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 30, 30,  0],\n",
       "       [ 0, 30, 30,  0],\n",
       "       [ 0, 30, 30,  0],\n",
       "       [ 0, 30, 30,  0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_conv = conv2d(vertical_array, v_edge_detector, verbose=False)\n",
    "vertical_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True, False],\n",
       "       [False,  True,  True, False],\n",
       "       [False,  True,  True, False],\n",
       "       [False,  True,  True, False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical_conv > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case II**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 11., 16.,  9.,  0.,  0.],\n",
       "       [ 0.,  0.,  3., 15., 16.,  6.,  0.,  0.],\n",
       "       [ 0.,  7., 15., 16., 16.,  2.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., 16., 16.,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 11., 16., 10.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(no1, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3., -38., -42.,  18.,  45.,  20.],\n",
       "       [-18., -35., -30.,  25.,  48.,  17.],\n",
       "       [-19., -40., -29.,  36.,  48.,  11.],\n",
       "       [-17., -41., -31.,  37.,  48.,  11.],\n",
       "       [ -3., -48., -45.,  33.,  48.,  15.],\n",
       "       [ -2., -43., -46.,  21.,  48.,  22.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no1_conv_v = conv2d(no1, v_edge_detector, verbose=False)\n",
    "no1_conv_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the ReLU function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., 18., 45., 20.],\n",
       "       [ 0.,  0.,  0., 25., 48., 17.],\n",
       "       [ 0.,  0.,  0., 36., 48., 11.],\n",
       "       [ 0.,  0.,  0., 37., 48., 11.],\n",
       "       [ 0.,  0.,  0., 33., 48., 15.],\n",
       "       [ 0.,  0.,  0., 21., 48., 22.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU(no1_conv_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how it captures the vertical edge?\n",
    "\n",
    "Let's try it again applying a horizontal edge detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1],\n",
       "       [ 0,  0,  0],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_edge_detector = v_edge_detector.T\n",
    "h_edge_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 11., 16.,  9.,  0.,  0.],\n",
       "       [ 0.,  0.,  3., 15., 16.,  6.,  0.,  0.],\n",
       "       [ 0.,  7., 15., 16., 16.,  2.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., 16., 16.,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., 16., 16.,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 11., 16., 10.,  0.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(no1, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.,  -6.,  -9.,  -7.,  -4.,  -1.],\n",
       "       [-22., -27., -20.,   2.,   7.,   7.],\n",
       "       [  2.,   1.,   1.,   2.,   3.,   3.],\n",
       "       [ 21.,  21.,  14.,  -4.,  -4.,  -4.],\n",
       "       [  0.,   0.,   0.,  -3.,  -3.,  -3.],\n",
       "       [  1.,   6.,   6.,   1.,  -4.,  -4.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no1_conv_h = conv2d(no1, h_edge_detector, verbose=False)\n",
    "no1_conv_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False],\n",
       "       [False, False, False,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True, False, False, False],\n",
       "       [False, False, False, False, False, False],\n",
       "       [ True,  True,  True,  True, False, False]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no1_conv_h > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "We may also use the filter matrix values as parameters to be learned by backprop:\n",
    "\n",
    "![](media/pback.png)\n",
    "\n",
    "Just remember that the *Loss* will point out how fare we are from the actual target, and the learning rate together with the partial derivatives will update the weights, leading them to our goal of feature detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Convolutions over volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply convolution in the following form:\n",
    "\n",
    "$Image_{8x8x3} * Filter_{3x3x3} = Conv_{6x6}$\n",
    "\n",
    "We need to apply it to each channel at the same time.\n",
    "\n",
    "For each convolution, the output will be 2 dimensional:\n",
    "\n",
    "![](media/3dconv.png)\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('media/sunflower.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behold my mighty sunflower and its pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it's three (RGB) channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunf = np.asarray(image)\n",
    "sunf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vert_detect_3d = np.array([\n",
    "                            [\n",
    "                                [1, 0, -1],\n",
    "                                [1, 0, -1],\n",
    "                                [1, 0, -1]\n",
    "                            ],\n",
    "                            [\n",
    "                                [1, 0, -1],\n",
    "                                [1, 0, -1],\n",
    "                                [1, 0, -1]\n",
    "                            ],\n",
    "                            [\n",
    "                                [1, 0, -1],\n",
    "                                [1, 0, -1],\n",
    "                                [1, 0, -1]\n",
    "                            ]\n",
    "                        ])\n",
    "\n",
    "vert_detect_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hor_detect_3d = np.array([\n",
    "                            [\n",
    "                                [1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [-1, -1, -1]\n",
    "                            ],\n",
    "                            [\n",
    "                                [1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [-1, -1, -1]\n",
    "                            ],\n",
    "                            [\n",
    "                                [1, 1, 1],\n",
    "                                [0, 0, 0],\n",
    "                                [-1, -1, -1]\n",
    "                            ]\n",
    "                        ])\n",
    "\n",
    "hor_detect_3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stride2d(_image, _filter, add_stride=0):\n",
    "    coords = []\n",
    "    x = 0\n",
    "    y = 0\n",
    "    z = 0\n",
    "\n",
    "    f_h = _filter.shape[0]\n",
    "    f_w = _filter.shape[1]\n",
    "    f_z = _filter.shape[2]\n",
    "    \n",
    "    img_h = _image.shape[0]\n",
    "    img_w = _image.shape[1]\n",
    "    img_z = _image.shape[2]\n",
    "        \n",
    "    for line in range(img_h):\n",
    "\n",
    "        if line + f_h <= img_h:\n",
    "                x_start = line\n",
    "                x_end = line + f_h\n",
    "\n",
    "        for col in range(img_w):\n",
    "\n",
    "            if col + f_w <= img_w:\n",
    "                y_start = col\n",
    "                y_end = col +  f_w\n",
    "\n",
    "            coords.append([x_start, x_end, y_start, y_end])\n",
    "\n",
    "        out = np.unique(coords, axis=0)\n",
    "    return out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def conv3d(_image, _filter, add_stride=0, verbose=False):\n",
    "    convs = []\n",
    "    sums = []\n",
    "    coords = stride2d(_image, _filter)\n",
    "    f_x = _filter.shape[0]\n",
    "    f_y = _filter.shape[1]\n",
    "    f_z = _filter.shape[2]\n",
    "    for xyc in coords:\n",
    "        # x\n",
    "        s_x = xyc[0]\n",
    "        e_x = xyc[1]\n",
    "        # y\n",
    "        s_y = xyc[2]\n",
    "        e_y = xyc[3]\n",
    "        cube = _image[s_x:e_x, s_y:e_y, :]\n",
    "        conv = cube * _filter\n",
    "        total = np.sum(conv)\n",
    "        convs.append(total)\n",
    "        sums.append(total)\n",
    "        if verbose == True:\n",
    "            print('Coords: [{}:{}, {}:{}, {}]'.format(s_x, e_x, s_y, e_y, ':'))\n",
    "            print('Slice:\\n{}'.format(cube))\n",
    "            print('Conv:\\n{}'.format(conv))\n",
    "            print('Sum: {}'.format(total) + '\\n')\n",
    "    r_h = _image.shape[0] - f_x + 1\n",
    "    r_w = _image.shape[1] - f_y + 1\n",
    "    r = np.array(sums).reshape(r_h, r_w)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sunf_conv = conv3d(_image=sunf, _filter=vert_detect_3d, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 626,  992, 1128, 1173, 1073,  636],\n",
       "        [ 628, 1054, 1231, 1264, 1116,  657],\n",
       "        [ 627,  872,  872,  908,  940,  665],\n",
       "        [ 377,  500,  495,  501,  536,  402],\n",
       "        [ 153,  126,   94,  121,  200,  197],\n",
       "        [ -49,  -13,   69,   89,   35,   19]]), (6, 6))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunf_conv, sunf_conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poolWindow(_in, _w_size):\n",
    "    i_x = _in.shape[0]\n",
    "    i_y = _in.shape[1]\n",
    "    coords = []\n",
    "    for x in range(i_x):\n",
    "        for y in range(i_y):\n",
    "            start = x, y\n",
    "            end = x + _w_size, y + _w_size\n",
    "            if end[0] <= i_x:\n",
    "                if end[1] <= i_y:\n",
    "                    coords.append([start, end])\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxPool(_in, _w_size, pretty=False):\n",
    "    print('input shape = {}\\n'.format(_in.shape))\n",
    "    coords = poolWindow(_in, _w_size)\n",
    "    pools = []\n",
    "    output = ''\n",
    "    for c in coords:\n",
    "        x_start = c[0][0]\n",
    "        x_end = c[1][0]\n",
    "        y_start = c[0][1]\n",
    "        y_end = c[1][1]\n",
    "        window = _in[x_start:x_end, y_start:y_end]\n",
    "        maxpool = np.max(window)\n",
    "        pools.append(maxpool)\n",
    "        if pretty == True:\n",
    "            print('x: {} -> {}, y: {} -> {}'.format(x_start, x_end, y_start, y_end))\n",
    "            print('window:\\n{}'.format(window))\n",
    "            print('max pool = {}\\n'.format(maxpool))\n",
    "    out_shape_x = floor((_in.shape[0] - _w_size) + 1)\n",
    "    out_shape_y = floor((_in.shape[1] - _w_size) + 1)\n",
    "    output = np.array(pools).reshape(out_shape_x,\n",
    "                                     out_shape_y)\n",
    "    print('output shape = {}'.format(output.shape))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape = (6, 6)\n",
      "\n",
      "output shape = (4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1231, 1264, 1264, 1264],\n",
       "       [1231, 1264, 1264, 1264],\n",
       "       [ 872,  908,  940,  940],\n",
       "       [ 500,  501,  536,  536]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maxPool(sunf_conv, 3, True)\n",
    "maxPool(sunf_conv, 3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it!\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
